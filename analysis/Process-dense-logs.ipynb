{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data location\n",
    "\n",
    "**In order to run this notebook, you need to first download the raw data from Dryad.**  \n",
    "https://doi.org/10.5061/dryad.bnzs7h4c4\n",
    "\n",
    "```DATA_DIR``` in the cell below must provide a path to the raw data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'raw_data' # <--- Fill in after downloading the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "# Pre-processing functions\n",
    "#  \n",
    "## Analyzing resource flow between agents\n",
    "BaseFlow sets up a base class used by subsequent analysis classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFlow:\n",
    "    def __init__(self, log, remap_by_skill=False):\n",
    "        self._log = log\n",
    "        self._t = len(self._log['states']) - 1\n",
    "\n",
    "        self._s0 = self._log['states'][0]\n",
    "        self._num_agents = len(self._s0) - 1\n",
    "\n",
    "        self._remap_by_skill = bool(remap_by_skill)\n",
    "        if self._remap_by_skill:\n",
    "            assert 'build_payment' in self._log['states'][0]['0']\n",
    "            build_skills = np.array([self._s0[str(i)]['build_payment'] for i in range(self.num_agents)])\n",
    "            self._aidx = np.argsort(build_skills).tolist()\n",
    "        else:\n",
    "            self._aidx = list(range(self.num_agents))\n",
    "\n",
    "        self._decay_array = np.arange(self._t)[::-1]\n",
    "\n",
    "    @property\n",
    "    def num_agents(self):\n",
    "        return self._num_agents\n",
    "\n",
    "    @property\n",
    "    def remap_by_skill(self):\n",
    "        return self._remap_by_skill\n",
    "\n",
    "    @property\n",
    "    def aidx(self):\n",
    "        return self._aidx\n",
    "\n",
    "    @property\n",
    "    def env_flow(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @property\n",
    "    def interaction_flow(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_weighted_sum(self, x, decay):\n",
    "        n = x.shape[0]\n",
    "        assert 0 <= decay <= 1.0\n",
    "        t_back = self._decay_array[-n:]\n",
    "        t_weights = decay ** t_back\n",
    "        t_weights[t_weights < 0.01] = 0.0\n",
    "        for _ in range(1, len(x.shape)):\n",
    "            t_weights = t_weights[:, None]\n",
    "        return np.sum(x * t_weights, axis=0)\n",
    "\n",
    "    def direction_flow(self, dst, src, t_s=0, t_e=None, decay=1.0):\n",
    "        dst = int(dst)\n",
    "        assert 0 <= dst < self.num_agents\n",
    "\n",
    "        if t_e is None:\n",
    "            t_e = self._t\n",
    "\n",
    "        # From the environment to an agent\n",
    "        if isinstance(src, str) or dst == src:\n",
    "            src = src.lower()[0]\n",
    "            assert src == 'e'\n",
    "\n",
    "            to_dst_from_env = self.get_weighted_sum(self.env_flow[t_s:t_e, dst], decay)\n",
    "            return to_dst_from_env\n",
    "\n",
    "        # From an agent to another agent\n",
    "        else:\n",
    "            src = int(src)\n",
    "            assert 0 <=src < self.num_agents\n",
    "\n",
    "            to_dst_from_src = self.get_weighted_sum(self.interaction_flow[t_s:t_e, dst, src], decay)\n",
    "            return to_dst_from_src\n",
    "\n",
    "    def get_net_flow_matrix(self, t_s=0, t_e=None, decay=1.0):\n",
    "        if t_e is None:\n",
    "            t_e = self._t\n",
    "\n",
    "        # Diagonal entries denote flow created by interactions with the environment (compute last)\n",
    "        # Off-diagnonal entries denote flow created by interactions with other agents\n",
    "\n",
    "        # First, compute direction flows for agent-to-agent interactions\n",
    "        flow_matrix = self.get_weighted_sum(self.interaction_flow[t_s:t_e], decay)\n",
    "\n",
    "        # Subtract incoming from outgoing and rectify (so that edges only show positive net flow)\n",
    "        flow_matrix = np.maximum(0, flow_matrix - flow_matrix.T)\n",
    "\n",
    "        # Add flow from the environment\n",
    "        flow_matrix = flow_matrix + np.diag(self.get_weighted_sum(self.env_flow[t_s:t_e], decay))\n",
    "\n",
    "        return flow_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResourceFlow tracks the flow of resources (i.e. Stone or Wood) from gathering and between agents via trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceFlow(BaseFlow):\n",
    "    def __init__(self, log, resource, remap_by_skill=False):\n",
    "        super().__init__(log, remap_by_skill)\n",
    "\n",
    "        assert 'Gather' in self._log\n",
    "        self._resource = resource\n",
    "\n",
    "        self._gathers = np.zeros((self._t, self.num_agents))\n",
    "        self._trades  = np.zeros((self._t, self.num_agents, self.num_agents))\n",
    "        self._prices  = np.zeros((self._t, self.num_agents, self.num_agents))\n",
    "\n",
    "        self._organize_gathers()\n",
    "        self._organize_trades()\n",
    "\n",
    "    @property\n",
    "    def resource(self):\n",
    "        return self._resource\n",
    "\n",
    "    @property\n",
    "    def gathers(self):\n",
    "        return self._gathers\n",
    "\n",
    "    @property\n",
    "    def trades(self):\n",
    "        return self._trades\n",
    "    \n",
    "    @property\n",
    "    def prices(self):\n",
    "        return self._prices\n",
    "\n",
    "    def _organize_gathers(self):\n",
    "        self._gathers *= 0\n",
    "\n",
    "        for t, gathers in enumerate(self._log['Gather']):\n",
    "            for gather in gathers:\n",
    "                if gather['resource'] == self.resource:\n",
    "                    self._gathers[t, gather['agent']] += gather['n']\n",
    "\n",
    "        self._gathers = self._gathers[:, self.aidx]\n",
    "\n",
    "    def _organize_trades(self):\n",
    "        self._trades *= 0\n",
    "\n",
    "        if 'Trade' not in self._log:\n",
    "            return\n",
    "\n",
    "        for t, trades in enumerate(self._log['Trade']):\n",
    "            if isinstance(trades, dict):\n",
    "                trades = trades['trades']\n",
    "            for trade in trades:\n",
    "                if trade['commodity'] == self.resource:\n",
    "                    self._trades[t, trade['buyer'], trade['seller']] += 1\n",
    "                    self._prices[t, trade['buyer'], trade['seller']] += trade['price']\n",
    "\n",
    "        self._trades = self._trades[:, self.aidx]\n",
    "        self._trades = self._trades[:, :, self.aidx]\n",
    "        self._prices = self._prices[:, self.aidx]\n",
    "        self._prices = self._prices[:, :, self.aidx]\n",
    "        \n",
    "\n",
    "    @property\n",
    "    def env_flow(self):\n",
    "        return self.gathers\n",
    "\n",
    "    @property\n",
    "    def interaction_flow(self):\n",
    "        return self.trades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IncomeFlow tracks the flow of Coin from building and between agents via trading, and (optionally) as resulting from redistribution of tax revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IncomeFlow(BaseFlow):\n",
    "    def __init__(self, log, include_redistribution=False, remap_by_skill=False):\n",
    "        super().__init__(log, remap_by_skill)\n",
    "\n",
    "        assert 'Build' in self._log\n",
    "\n",
    "        self._include_redistribution = bool(include_redistribution)\n",
    "\n",
    "        self._builds = np.zeros((self._t, self.num_agents))\n",
    "        self._trades = np.zeros((self._t, self.num_agents, self.num_agents))\n",
    "        self._redist = np.zeros((self._t, self.num_agents, self.num_agents))\n",
    "\n",
    "        self._organize_builds()\n",
    "        self._organize_trades()\n",
    "        self._organize_redist()\n",
    "\n",
    "    @property\n",
    "    def include_redistribution(self):\n",
    "        return self._include_redistribution\n",
    "\n",
    "    @property\n",
    "    def builds(self):\n",
    "        return self._builds\n",
    "\n",
    "    @property\n",
    "    def trades(self):\n",
    "        return self._trades\n",
    "\n",
    "    @property\n",
    "    def redist(self):\n",
    "        return self._redist\n",
    "\n",
    "    def _organize_builds(self):\n",
    "        self._builds *= 0\n",
    "\n",
    "        for t, builds in enumerate(self._log['Build']):\n",
    "            if isinstance(builds, dict):\n",
    "                builds = builds['builds']\n",
    "            for build in builds:\n",
    "                self._builds[t, build['builder']] += build['income']\n",
    "\n",
    "        self._builds = self._builds[:, self.aidx]\n",
    "\n",
    "    def _organize_trades(self):\n",
    "        self._trades *= 0\n",
    "\n",
    "        if 'Trade' not in self._log:\n",
    "            return\n",
    "\n",
    "        for t, trades in enumerate(self._log['Trade']):\n",
    "            if isinstance(trades, dict):\n",
    "                trades = trades['trades']\n",
    "            for trade in trades:\n",
    "                self._trades[t, trade['seller'], trade['buyer']] += trade['income']\n",
    "\n",
    "        self._trades = self._trades[:, self.aidx]\n",
    "        self._trades = self._trades[:, :, self.aidx]\n",
    "\n",
    "    def _organize_redist(self):\n",
    "        self._redist *= 0\n",
    "\n",
    "        if 'PeriodicTax' not in self._log:\n",
    "            return\n",
    "\n",
    "        if not self.include_redistribution:\n",
    "            return\n",
    "\n",
    "        for t, taxes in enumerate(self._log['PeriodicTax']):\n",
    "            if taxes:\n",
    "                for i in range(self.num_agents):\n",
    "                    tax_paid = taxes[str(i)]['tax_paid']\n",
    "                    redist_share = tax_paid / self.num_agents\n",
    "                    for dst in range(self.num_agents):\n",
    "                        if dst == i:\n",
    "                            continue\n",
    "                        self._redist[t, dst, i] = redist_share\n",
    "\n",
    "        self._redist = self._redist[:, self.aidx]\n",
    "        self._redist = self._redist[:, :, self.aidx]\n",
    "\n",
    "    @property\n",
    "    def env_flow(self):\n",
    "        return self.builds\n",
    "\n",
    "    @property\n",
    "    def interaction_flow(self):\n",
    "        return self.trades + self.redist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics functions\n",
    "Helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_agents(log):\n",
    "    \"\"\"Get the number of non-planner agents.\"\"\"\n",
    "    s0 = log['states'][0]\n",
    "    return len(s0) - 1\n",
    "\n",
    "def sort_by_skill(array_getter_func):\n",
    "    \"\"\"Useful decorator to automatically return agent-wise statistics as sorted by build skill.\"\"\"\n",
    "    def sorted_array_getter_func(log):\n",
    "        s0 = log['states'][0]\n",
    "        skills = [s0[str(i)]['build_payment'] for i in range(get_num_agents(log))]\n",
    "        s_idx = np.argsort(skills)\n",
    "        \n",
    "        out = array_getter_func(log)\n",
    "        \n",
    "        if isinstance(out, np.ndarray):\n",
    "            return out[s_idx]\n",
    "        if isinstance(out, (tuple, list)):\n",
    "            return [array[s_idx] for array in out]\n",
    "        if isinstance(out, dict):\n",
    "            return {k: v[s_idx] for k, v in out.items()}\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    return sorted_array_getter_func    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build-skill-sorted, agent-wise stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sort_by_skill\n",
    "def get_income_and_tax_stats(log):\n",
    "    \"\"\"Get build-skill-sorted, agent-wise stats related to labor, income, and taxes.\"\"\"\n",
    "    nA = get_num_agents(log)\n",
    "    \n",
    "    if 'PeriodicTax' not in log:\n",
    "        tax_paid = np.zeros(nA)\n",
    "        lump_sum = np.zeros(nA)\n",
    "        \n",
    "    else:\n",
    "        periods = log['PeriodicTax'][99::100]\n",
    "        tax_paid = np.array([[period[str(i)]['tax_paid'] for i in range(nA)] for period in periods]).sum(0)\n",
    "        lump_sum = np.array([[period[str(i)]['lump_sum'] for i in range(nA)] for period in periods]).sum(0)\n",
    "        \n",
    "    net_tax_paid = tax_paid - lump_sum\n",
    "        \n",
    "    sT = log['states'][-1]\n",
    "    \n",
    "    post_tax_income = np.array([sT[str(i)]['inventory']['Coin']+sT[str(i)]['escrow']['Coin'] for i in range(nA)])\n",
    "    pre_tax_income = post_tax_income + net_tax_paid\n",
    "    \n",
    "    labor = np.array([sT[str(i)]['endogenous']['Labor'] for i in range(nA)])\n",
    "    \n",
    "    return {\n",
    "        'pre_tax_income': pre_tax_income,\n",
    "        'post_tax_income': post_tax_income,\n",
    "        'tax_paid': tax_paid,\n",
    "        'lump_sum': lump_sum,\n",
    "        'net_tax_paid': net_tax_paid,\n",
    "        'labor': labor,\n",
    "    }\n",
    "\n",
    "@sort_by_skill\n",
    "def get_net_trade_income(log):\n",
    "    \"\"\"Get build-skill-sorted, agent-wise net income specifically from trading.\"\"\"\n",
    "    i_flow = IncomeFlow(log, include_redistribution=False, remap_by_skill=False)\n",
    "    trade_flow = i_flow.trades.sum(0)\n",
    "    revenue = trade_flow.sum(1)\n",
    "    cost = trade_flow.sum(0)\n",
    "    return {\n",
    "        'net_trade_income': revenue - cost\n",
    "    }\n",
    "\n",
    "@sort_by_skill\n",
    "def get_net_build_income(log):\n",
    "    \"\"\"Get build-skill-sorted, agent-wise net income specifically from building.\"\"\"\n",
    "    i_flow = IncomeFlow(log, include_redistribution=False, remap_by_skill=False)\n",
    "    return {\n",
    "        'net_build_income': i_flow.builds.sum(0)\n",
    "    }\n",
    "\n",
    "@sort_by_skill\n",
    "def get_gather_info(log):\n",
    "    \"\"\"Get build-skill-sorted, agent-wise resource gathering counts.\"\"\"\n",
    "    w_flow = ResourceFlow(log, 'Wood', remap_by_skill=False)\n",
    "    s_flow = ResourceFlow(log, 'Stone', remap_by_skill=False)\n",
    "    return {\n",
    "        'total_wood_collected':  w_flow.gathers.sum(0),\n",
    "        'total_stone_collected': s_flow.gathers.sum(0),\n",
    "        'total_resources_collected': w_flow.gathers.sum(0) + s_flow.gathers.sum(0),\n",
    "    }\n",
    "\n",
    "@sort_by_skill\n",
    "def get_tax_gaming_info(log):\n",
    "    \"\"\"Get build-skill-sorted, agent-wise tax due based on actual incomes and temporally smoothed incomes.\"\"\"\n",
    "    if 'PeriodicTax' not in log:\n",
    "        zs = np.zeros(get_num_agents(log))\n",
    "        return {\n",
    "            'tax_burden_actual_inc': zs,\n",
    "            'tax_burden_average_inc': zs\n",
    "        }\n",
    "    \n",
    "    def taxes_due(income, cutoffs, rates):\n",
    "        \"\"\"Return the total amount of taxes due at this income level.\"\"\"\n",
    "        past_cutoff = np.maximum(0, income - cutoffs)\n",
    "        bracket_sizes = np.concatenate([cutoffs[1:]-cutoffs[:-1], [np.inf]])\n",
    "        bin_income = np.minimum(bracket_sizes, past_cutoff)\n",
    "        bin_taxes = rates * bin_income\n",
    "        return np.sum(bin_taxes)\n",
    "    \n",
    "    nA = get_num_agents(log)\n",
    "    \n",
    "    periods = log['PeriodicTax'][99::100]\n",
    "    \n",
    "    incomes = np.array([[period[str(i)]['income'] for i in range(nA)] for period in periods])\n",
    "    avg_inc = incomes.mean(0)\n",
    "    \n",
    "    due_actual_inc  = np.zeros((len(periods), nA))\n",
    "    due_average_inc = np.zeros((len(periods), nA))\n",
    "    \n",
    "    for ip, period in enumerate(periods):\n",
    "        cutoffs = np.array(period['cutoffs'])\n",
    "        rates = np.array(period['schedule'])\n",
    "        for ia in range(nA):\n",
    "            due_actual_inc[ip, ia] = taxes_due(incomes[ip, ia], cutoffs, rates)\n",
    "            due_average_inc[ip, ia] = taxes_due(avg_inc[ia], cutoffs, rates)\n",
    "            \n",
    "    return {\n",
    "        'tax_burden_actual_inc': due_actual_inc.sum(0),\n",
    "        'tax_burden_average_inc': due_average_inc.sum(0),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General, non-agent-specific stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_info(log):\n",
    "    \"\"\"Get average trading prices for Wood and Stone.\"\"\"\n",
    "    w_flow = ResourceFlow(log, 'Wood', remap_by_skill=False)\n",
    "    s_flow = ResourceFlow(log, 'Stone', remap_by_skill=False)\n",
    "    return {\n",
    "        'avg_wood_price':  w_flow.prices.sum() / w_flow.trades.sum(),\n",
    "        'avg_stone_price': s_flow.prices.sum() / s_flow.trades.sum(),\n",
    "    }\n",
    "\n",
    "def get_avg_tax_schedule(log):\n",
    "    \"\"\"Get the average tax schedule throughout the episode.\"\"\"\n",
    "    if 'PeriodicTax' not in log:\n",
    "        return {'avg_tax_schedule': np.zeros(7)}\n",
    "    periods = log['PeriodicTax'][99::100]\n",
    "    return {\n",
    "        'avg_tax_schedule': np.array([period['schedule'] for period in periods]).mean(0)\n",
    "    }\n",
    "\n",
    "\n",
    "def get_bracket_occupancies(log):\n",
    "    \"\"\"Get the fraction of incomes within each tax bracket throughout the episode.\"\"\"\n",
    "    def get_all_incomes(log):\n",
    "        incomes = []\n",
    "        nA = get_num_agents(log)\n",
    "\n",
    "        if 'PeriodicTax' not in log:\n",
    "            def get_agent_coin(idx, t):\n",
    "                return log['states'][t][str(idx)]['inventory']['Coin'] + log['states'][t][str(idx)]['escrow']['Coin']\n",
    "            for idx in range(nA):\n",
    "                last_coin = get_agent_coin(idx, 0)\n",
    "                for t in [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]:\n",
    "                    this_coin = get_agent_coin(idx, t)\n",
    "                    incomes.append(this_coin - last_coin)\n",
    "                    last_coin = float(this_coin)\n",
    "\n",
    "        else:\n",
    "            for p in log['PeriodicTax'][99::100]:\n",
    "                for i in range(nA):\n",
    "                    incomes.append(p[str(i)]['income'])\n",
    "\n",
    "        return np.array(incomes)\n",
    "    \n",
    "    incomes = get_all_incomes(log)\n",
    "    \n",
    "    bracket_cutoffs = np.array([-np.inf, 9700, 39475, 84200, 160725, 204100, 510300]) / 1000\n",
    "    \n",
    "    bracket_idx = np.sum(incomes[:, None] > bracket_cutoffs[None], 1) - 1\n",
    "    \n",
    "    return {\n",
    "#         'raw_incomes': incomes,\n",
    "        'avg_bracket_occupancy': np.array([np.mean(bracket_idx == i) for i in range(7)])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined pre-processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_stats(log):\n",
    "    \"\"\"Processes a dense log into a stats dictionary using the pre-processing functions.\"\"\"\n",
    "    stats = {}\n",
    "    stats.update(get_income_and_tax_stats(log))\n",
    "    stats.update(get_net_trade_income(log))\n",
    "    stats.update(get_net_build_income(log))\n",
    "    stats.update(get_gather_info(log))\n",
    "    stats.update(get_tax_gaming_info(log))\n",
    "    stats.update(get_avg_tax_schedule(log))\n",
    "    stats.update(get_bracket_occupancies(log))\n",
    "    stats.update(get_price_info(log))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "# Functions to batch process the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dense_logs_of_run(run_dir, verbose=True):\n",
    "    \"\"\"Process the dense logs from this run directory that were used in the paper's analyses.\"\"\"\n",
    "    \n",
    "    if not os.path.isdir(run_dir):\n",
    "        raise FileNotFoundError(\"The run directory does not exist.\")\n",
    "        \n",
    "    logs_dir = os.path.join(run_dir, 'experiment_dense_logs')\n",
    "    if not os.path.isdir(logs_dir):\n",
    "        raise FileNotFoundError('There do not appear to be any paper logs in this run directory.')\n",
    "    paper_log_filenames = os.listdir(logs_dir)\n",
    "    paper_log_filenames = sorted(paper_log_filenames, key=lambda f: int(f.split('.')[0].split('_')[-1]))\n",
    "\n",
    "    if verbose:\n",
    "        print('Processing {} dense logs from {}'.format(len(paper_log_filenames), run_dir))\n",
    "    \n",
    "    episode_dicts = []\n",
    "    for file in paper_log_filenames:\n",
    "        log_path = os.path.join(logs_dir, file)\n",
    "        with open(log_path, 'r') as f:\n",
    "            log = json.load(f)\n",
    "        episode_dicts.append(\n",
    "            collect_stats(log)\n",
    "        )\n",
    "        \n",
    "    return episode_dicts\n",
    "\n",
    "def process_dense_logs_of_group(group_dir, verbose=True):\n",
    "    \"\"\"Process all the dense logs from this run group that were used in the paper's analyses.\"\"\"\n",
    "    \n",
    "    if not os.path.isdir(group_dir):\n",
    "        raise FileNotFoundError(\"The group directory does not exist.\")\n",
    "        \n",
    "    if verbose:\n",
    "        print('Processing dense logs under {}'.format(group_dir))\n",
    "        \n",
    "    run_dirs = []\n",
    "    run_idx = 1\n",
    "    while True:\n",
    "        run_dir = os.path.join(group_dir, 'seed_{}'.format(run_idx))\n",
    "        if os.path.isdir(run_dir):\n",
    "            run_dirs.append(run_dir)\n",
    "            run_idx += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    episode_dicts = []\n",
    "    for idx, run_dir in enumerate(run_dirs):\n",
    "        if verbose:\n",
    "            print('\\tSeed {}'.format(idx+1))\n",
    "        run_dicts = process_dense_logs_of_run(run_dir, verbose=False)\n",
    "        episode_dicts += run_dicts\n",
    "        \n",
    "    return episode_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_dictionary_of_setting(scenario, objective, save=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Gets the group-wise dictionary of processed stats for a setting (defined by the scenario and objective).\n",
    "    \n",
    "    Args:\n",
    "        scenario (str): The name of the scenario used in this setting.\n",
    "        objective (str): The name of the social welfare objective used in this setting.\n",
    "        save (bool): Whether to save the statistics dictionary. Defaults to True.\n",
    "        verbose (bool): Whether to use verbose printouts. Defaults to True.\n",
    "        \n",
    "    Returns:\n",
    "        stats_dict (dict): A dictionary of {group: episode_dict_list}, where each group is one of the 4 tax\n",
    "            models and episode_dict_list is a list of statistics processed from all of the dense logs\n",
    "            associated with that group (for the given objective, if applicable).\n",
    "    \"\"\"\n",
    "    \n",
    "    scenario = scenario.lower()\n",
    "    objective = objective.lower()\n",
    "    \n",
    "    assert scenario in [\n",
    "        'open_quadrant_4',\n",
    "        'open_quadrant_10',\n",
    "        'split_012',\n",
    "        'split_27',\n",
    "        'split_45',\n",
    "        'split_789',\n",
    "    ]\n",
    "    \n",
    "    assert objective in [\n",
    "        'eq*prod',\n",
    "        'iiwu',\n",
    "    ]\n",
    "    \n",
    "    scenario_dir = os.path.join(DATA_DIR, scenario)\n",
    "    \n",
    "    obj_tag = '({})'.format(objective)\n",
    "    has_specific_saez = 'saez'+obj_tag in os.listdir(scenario_dir)\n",
    "    \n",
    "    # We will process 4 groups: Free Market, US Federal, Saez Formula, and AI Economist\n",
    "    group_dirs = {\n",
    "        'Free Market': os.path.join(scenario_dir, 'fm'),\n",
    "        'US Federal': os.path.join(scenario_dir, 'us'),\n",
    "        'Saez Formula': os.path.join(scenario_dir, 'saez' + (obj_tag if has_specific_saez else '')),\n",
    "        'AI Economist': os.path.join(scenario_dir, 'aie' + obj_tag)\n",
    "    }\n",
    "    \n",
    "    # Process each group\n",
    "    stats_dict = {}\n",
    "    for group, group_dir in group_dirs.items():\n",
    "        if verbose:\n",
    "            print(group)\n",
    "        stats_dict[group] = process_dense_logs_of_group(group_dir, verbose=verbose)\n",
    "    \n",
    "    if save:\n",
    "        filename = 'preprocessed_dense_logs_stats_dict-{}-{}.pkl'.format(\n",
    "            scenario,\n",
    "            'eq_times_prod' if objective=='eq*prod' else 'iiwu'\n",
    "        )\n",
    "        if verbose:\n",
    "            print('\\n\\nSaving processed statistics to:\\n\\t{}'.format(filename))\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(stats_dict, f)\n",
    "            \n",
    "    return stats_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "# Perform the pre-processing\n",
    "\n",
    "**Note**: The preprocessed data used by the paper are already stored in  \n",
    "```preprocessed_dense_logs_stats_dict-open_quadrant_4-eq_times_prod-used_in_paper_analyses.pkl```.\n",
    "\n",
    "This notebook serves as a reference for how that preprocessing was performed.\n",
    "Additionally, it allows you to process other settings and save them for analysis in  \n",
    "```Experiment-analysis-and-visualization.ipynb```.\n",
    "\n",
    "An example for the code you would run to do so is provided in the next cell. It is, by default, commented so you don't accidentally run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_statistics_dictionary_of_setting(\n",
    "#     scenario='open_quadrant_4',\n",
    "#     objective='iiwu',\n",
    "#     save=True,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
